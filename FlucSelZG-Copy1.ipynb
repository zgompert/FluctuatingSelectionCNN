{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82d9c5bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/uufs/chpc.utah.edu/common/home/u6031121'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f1bfb0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/uufs/chpc.utah.edu/common/home/gompert-group4/projects/fluctCNN/CNNTrainingData\n"
     ]
    }
   ],
   "source": [
    "%cd /uufs/chpc.utah.edu/common/home/gompert-group4/projects/fluctCNN/CNNTrainingData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d9c5c080",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9e17081",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "directory_path ='/uufs/chpc.utah.edu/common/home/gompert-group4/projects/fluctCNN/CNNTrainingData'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8498b09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# making a list of all csv files\n",
    "csv_files = [file for file in os.listdir(directory_path) if file.endswith('.csv')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "835e4141",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(csv_files))\n",
    "#print(csv_files)\n",
    "df=pd.read_csv(csv_files[1], header=None, sep=' ', dtype='float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81d60c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting labels from file name of each CSV and storing it in a vector \"vec\"\n",
    "# my_list = csv_files[:]\n",
    "# vec = [item[:5] for item in my_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9db190c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing value of environment in each even columns in each CSV file by using \"min-max scaling\"\n",
    "# for file in csv_files:\n",
    "#     filepath = file  # You can modify the filepath if the CSV files are in a different directory\n",
    "#     filename = os.path.splitext(file)[0]  # Extract the filename without extension\n",
    "\n",
    "#     df = pd.read_csv(filepath)  # Read the CSV file into a pandas DataFrame\n",
    "\n",
    "#     # Normalize even columns using min-max scaling\n",
    "#     even_cols = df.columns[0::2]  # Select even columns\n",
    "#     df[even_cols] = ((df[even_cols] + 2)/ 4)\n",
    "\n",
    "#     # Save the normalized DataFrame to a new CSV file with the same name\n",
    "#     normalized_filepath = f\"{filename}_normalized.csv\"\n",
    "#     df.to_csv(normalized_filepath, index=False)\n",
    "\n",
    "#     print(f\"Normalized file saved: {normalized_filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1685c407",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "# csvn_files = [file for file in os.listdir(directory_path) if file.endswith('_normalized.csv')]\n",
    "print(len(csv_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf53de0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "a =[]\n",
    "for matrix in csv_files:\n",
    "    df=pd.read_csv(matrix, header=None, sep=' ', dtype='float32')\n",
    "    if df.shape==(10, 20):\n",
    "        a.append(1)\n",
    "print(sum(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b1e1ad1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the CSV matrices into numpy arrays\n",
    "matrices = []\n",
    "out_vec = []\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file, header=None, sep=' ', dtype='float32')\n",
    "    #df = df.iloc[1:, 1:].values\n",
    "    #df = df.astype('float32')\n",
    "    matrix = df\n",
    "    matrices.append(matrix)\n",
    "    # appending first five letters to out_vec as labels\n",
    "    label = file[:5]\n",
    "    out_vec.append(label)\n",
    "\n",
    "#print(matrices)\n",
    "# Convert the list of matrices into a single numpy array\n",
    "# input_data = np.array(matrices)\n",
    "# output_data = np.array(out_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "34740d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # to check how many entries are there in the matrices object\n",
    "# a =[]\n",
    "# for matrix in matrices:\n",
    "#     a.append(1)\n",
    "# print(sum(a))\n",
    "\n",
    "\n",
    "# a =[]\n",
    "# for matrix in out_vec:\n",
    "#     a.append(1)\n",
    "# print(sum(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "44b36922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # To double check whether the shapes of the matrices are same or not\n",
    "# shapes=[matrix.shape for matrix in matrices]\n",
    "# if len(set(shapes))>1:\n",
    "#     print(\"matrices have different shapes\")\n",
    "# else:\n",
    "#     print(\"matrices have same sahpe\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c5feec4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10, 20)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting input arrays of matrices into \n",
    "input_arrays = np.stack(matrices)\n",
    "#print(input_arrays)\n",
    "input_arrays.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e08a8f27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# converting label arrays of matrices into \n",
    "# import keras as keras\n",
    "# from keras_utils import to_categorical\n",
    "# out_vecc=to_categorical(out_vec)\n",
    "# output_arrays = np.stack(out_vecc)\n",
    "# #print(input_arrays)\n",
    "# output_arrays.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f4ede86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Type1': 0, 'Type2': 1}\n"
     ]
    }
   ],
   "source": [
    "labels =out_vec\n",
    "label_mapping = {label: index for index, label in enumerate(set(labels))}\n",
    "print(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "719e1154",
   "metadata": {},
   "outputs": [],
   "source": [
    "integer_labels = np.array([label_mapping[label] for label in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6a56efa0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print(integer_labels)\n",
    "categorical_labels = tf.one_hot(integer_labels, depth=len(label_mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1ba0c49e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_labels = np.stack(categorical_labels)\n",
    "out_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "38c6ce68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2c91091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting numpy arrays to tf tensors\n",
    "input_tensor = tf.convert_to_tensor(input_arrays)\n",
    "# converting output arrays to tf tensors\n",
    "Label_tensor = tf.convert_to_tensor(out_labels)\n",
    "print(tf.is_tensor(Label_tensor))\n",
    "# to know shapes of input and label tensors\n",
    "input_tensor.shape \n",
    "Label_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f3321eeb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_arrays.shape\n",
    "input_arr = np.reshape(input_arrays, (10000, 10, 20, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "53c060ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # making values to two decimal places\n",
    "# input_tensorr = tf.round(tf.multiply(input_tensor, 1000))/1000\n",
    "# input_tensorr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cf4da844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # reshaping input tensor\n",
    "# input_tensorrr = tf.reshape(input_tensorr, shape=(10000, 10, 20, 1))\n",
    "# #input_tensorrr = tf.expand_dims(input_tensorr, axis=-1)\n",
    "# input_tensorrr.shape\n",
    "# #input_tensorrrx[[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f9a61d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "## dividing input and label data into training, testingsets 4k, 1k size\n",
    "from sklearn.model_selection import train_test_split\n",
    "input_train, input_test, output_train, output_test = train_test_split(input_arr, out_labels, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0a548314",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(output_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b12c75bf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "127/127 [==============================] - 1s 5ms/step - loss: 0.6944 - accuracy: 0.5025 - val_loss: 0.6946 - val_accuracy: 0.4711\n",
      "Epoch 2/25\n",
      "127/127 [==============================] - 1s 5ms/step - loss: 0.6915 - accuracy: 0.5316 - val_loss: 0.6959 - val_accuracy: 0.4800\n",
      "Epoch 3/25\n",
      "127/127 [==============================] - 1s 5ms/step - loss: 0.6877 - accuracy: 0.5353 - val_loss: 0.6962 - val_accuracy: 0.5233\n",
      "Epoch 4/25\n",
      "127/127 [==============================] - 1s 5ms/step - loss: 0.6811 - accuracy: 0.5562 - val_loss: 0.6864 - val_accuracy: 0.5544\n",
      "Epoch 5/25\n",
      "127/127 [==============================] - 1s 5ms/step - loss: 0.6749 - accuracy: 0.5672 - val_loss: 0.6861 - val_accuracy: 0.5544\n",
      "Epoch 6/25\n",
      "127/127 [==============================] - 1s 5ms/step - loss: 0.6657 - accuracy: 0.5812 - val_loss: 0.6907 - val_accuracy: 0.5567\n",
      "Epoch 7/25\n",
      "127/127 [==============================] - 1s 5ms/step - loss: 0.6564 - accuracy: 0.6052 - val_loss: 0.6763 - val_accuracy: 0.5889\n",
      "Epoch 8/25\n",
      "127/127 [==============================] - 1s 5ms/step - loss: 0.6468 - accuracy: 0.6167 - val_loss: 0.6858 - val_accuracy: 0.5800\n",
      "Epoch 9/25\n",
      "127/127 [==============================] - 1s 5ms/step - loss: 0.6336 - accuracy: 0.6330 - val_loss: 0.6804 - val_accuracy: 0.5811\n",
      "Epoch 10/25\n",
      "127/127 [==============================] - 1s 5ms/step - loss: 0.6158 - accuracy: 0.6506 - val_loss: 0.6846 - val_accuracy: 0.5711\n",
      "Epoch 11/25\n",
      "127/127 [==============================] - 1s 5ms/step - loss: 0.6070 - accuracy: 0.6673 - val_loss: 0.7062 - val_accuracy: 0.5489\n",
      "Epoch 12/25\n",
      "127/127 [==============================] - 1s 5ms/step - loss: 0.5861 - accuracy: 0.6775 - val_loss: 0.7259 - val_accuracy: 0.5578\n",
      "Epoch 13/25\n",
      "127/127 [==============================] - 1s 5ms/step - loss: 0.5653 - accuracy: 0.6979 - val_loss: 0.7104 - val_accuracy: 0.5733\n",
      "Epoch 14/25\n",
      "127/127 [==============================] - 1s 5ms/step - loss: 0.5377 - accuracy: 0.7228 - val_loss: 0.7399 - val_accuracy: 0.5600\n",
      "Epoch 15/25\n",
      "127/127 [==============================] - 1s 5ms/step - loss: 0.5084 - accuracy: 0.7484 - val_loss: 0.7617 - val_accuracy: 0.5400\n",
      "Epoch 16/25\n",
      "127/127 [==============================] - 1s 5ms/step - loss: 0.4743 - accuracy: 0.7723 - val_loss: 0.7810 - val_accuracy: 0.5378\n",
      "Epoch 17/25\n",
      "127/127 [==============================] - 1s 5ms/step - loss: 0.4338 - accuracy: 0.7974 - val_loss: 0.8492 - val_accuracy: 0.5433\n",
      "Epoch 18/25\n",
      "127/127 [==============================] - 1s 5ms/step - loss: 0.3896 - accuracy: 0.8289 - val_loss: 0.9227 - val_accuracy: 0.5322\n",
      "Epoch 19/25\n",
      "127/127 [==============================] - 1s 5ms/step - loss: 0.3409 - accuracy: 0.8574 - val_loss: 1.0124 - val_accuracy: 0.5267\n",
      "Epoch 20/25\n",
      "127/127 [==============================] - 1s 5ms/step - loss: 0.2845 - accuracy: 0.8899 - val_loss: 1.0538 - val_accuracy: 0.5544\n",
      "Epoch 21/25\n",
      "127/127 [==============================] - 1s 5ms/step - loss: 0.2321 - accuracy: 0.9168 - val_loss: 1.1783 - val_accuracy: 0.5233\n",
      "Epoch 22/25\n",
      "127/127 [==============================] - 1s 5ms/step - loss: 0.1805 - accuracy: 0.9463 - val_loss: 1.2604 - val_accuracy: 0.5478\n",
      "Epoch 23/25\n",
      "127/127 [==============================] - 1s 5ms/step - loss: 0.1395 - accuracy: 0.9638 - val_loss: 1.3457 - val_accuracy: 0.5578\n",
      "Epoch 24/25\n",
      "127/127 [==============================] - 1s 5ms/step - loss: 0.1011 - accuracy: 0.9798 - val_loss: 1.5151 - val_accuracy: 0.5411\n",
      "Epoch 25/25\n",
      "127/127 [==============================] - 1s 5ms/step - loss: 0.0686 - accuracy: 0.9920 - val_loss: 1.6952 - val_accuracy: 0.5367\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.5612 - accuracy: 0.5450\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Conv2D(32, kernel_size=(2, 2), activation=\"relu\", input_shape=(10, 20, 1)))\n",
    "model.add(layers.MaxPooling2D(pool_size=(1, 1)))\n",
    "model.add(layers.Conv2D(64, kernel_size=(2, 2), activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation=\"relu\"))\n",
    "model.add(layers.Dense(2, activation=\"sigmoid\"))\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "model.fit(input_train, output_train, batch_size=64, epochs=25, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(input_test, output_test)\n",
    "# print(\"Test Loss:\", loss)\n",
    "# print(\"Test Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
