{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7646f847",
   "metadata": {},
   "outputs": [],
   "source": [
    "### loading libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf57219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check available devices\n",
    "devices = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if len(devices) > 0:\n",
    "    print(\"GPU is available\")\n",
    "    for device in devices:\n",
    "        print(\"Device name:\", device.name)\n",
    "else:\n",
    "    print(\"No GPU is available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be167a8b",
   "metadata": {},
   "source": [
    "## Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e94e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ TRAINING DATA \n",
    "# changing directory to the data folder\n",
    "%cd /uufs/chpc.utah.edu/common/home/gompert-group4/projects/fluctCNN/DatafromUpdataCodeAugust25th/Trn/\n",
    "\n",
    "directory_path ='/uufs/chpc.utah.edu/common/home/gompert-group4/projects/fluctCNN/DatafromUpdataCodeAugust25th/Trn/'\n",
    "### making a list of all csv files\n",
    "csv_files = [file for file in os.listdir(directory_path) if file.endswith('.csv')]\n",
    "\n",
    "### processing the list of csv files to make arrays of input matrices and extracting output labels \n",
    "matrices = []\n",
    "out_vec = []\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file, header=None, sep=' ', dtype='float32')\n",
    "    matrices.append(df)\n",
    "    # appending first five letters to out_vec as labels\n",
    "    label = file[0:8]\n",
    "    out_vec.append(label)\n",
    "input_arrays = np.stack(matrices)\n",
    "inDa_trn = input_arrays.reshape((45000, 10, 20, 1))\n",
    "inDa_trn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb10ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### TRAINIG labels\n",
    "labels =out_vec\n",
    "# converting string values to integer calsses\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Initialize a LabelEncoder object\n",
    "label_encoder = LabelEncoder()\n",
    "# Fit the LabelEncoder to your string list and transform the string values into integer classes\n",
    "label_int = label_encoder.fit_transform(labels)\n",
    "#from keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "ouLa_trn =to_categorical(label_int)\n",
    "ouLa_trn.shape\n",
    "#print(ouLa_trn)\n",
    "ouLa_trn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b478579",
   "metadata": {},
   "source": [
    "## Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02db96b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ TEST DATA \n",
    "# changing directory to the data folder\n",
    "%cd /uufs/chpc.utah.edu/common/home/gompert-group4/projects/fluctCNN/DatafromUpdataCodeAugust25th/Tst/\n",
    "# importing test set\n",
    "directory_path ='/uufs/chpc.utah.edu/common/home/gompert-group4/projects/fluctCNN/DatafromUpdataCodeAugust25th/Tst/'\n",
    "### making a list of all csv files\n",
    "csv_files_t = [file for file in os.listdir(directory_path) if file.endswith('.csv')]\n",
    "\n",
    "### processing the list of csv files to make arrays of input matrices and extracting output labels \n",
    "matrices = []\n",
    "out_vec = []\n",
    "for file in csv_files_t:\n",
    "    df = pd.read_csv(file, header=None, sep=' ', dtype='float32')\n",
    "    matrices.append(df)\n",
    "    # appending first five letters to out_vec as labels\n",
    "    label = file[0:8]\n",
    "    out_vec.append(label)\n",
    "input_arrays = np.stack(matrices)\n",
    "inDa_tst = input_arrays.reshape((15000, 10, 20, 1))\n",
    "inDa_tst.dtype\n",
    "inDa_tst.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129028fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### TEST labels\n",
    "labels =out_vec\n",
    "# converting string values to integer calsses\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Initialize a LabelEncoder object\n",
    "label_encoder = LabelEncoder()\n",
    "# Fit the LabelEncoder to your string list and transform the string values into integer classes\n",
    "label_int = label_encoder.fit_transform(labels)\n",
    "#from keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "ouLa_tst =to_categorical(label_int)\n",
    "ouLa_tst.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791d0a8f",
   "metadata": {},
   "source": [
    "## Validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005c5be3",
   "metadata": {},
   "source": [
    "#### Independent validation set generated afresh from the simulation script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffdba8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ VALIDATION DATA \n",
    "# changing directory to the data folder\n",
    "%cd /uufs/chpc.utah.edu/common/home/gompert-group4/projects/fluctCNN/DatafromUpdataCodeAugust25th/val/\n",
    "# importing validation set\n",
    "directory_path ='/uufs/chpc.utah.edu/common/home/gompert-group4/projects/fluctCNN/DatafromUpdataCodeAugust25th/val/'\n",
    "### making a list of all csv files\n",
    "csv_files_v = [file for file in os.listdir(directory_path) if file.endswith('.csv')]\n",
    "#print(len(csv_files))\n",
    "### processing the list of csv files to make arrays of input matrices and extracting output labels \n",
    "matrices = []\n",
    "out_vec = []\n",
    "for file in csv_files_v:\n",
    "    df = pd.read_csv(file, header=None, sep=' ', dtype='float32')\n",
    "    matrices.append(df)\n",
    "    # appending first five letters to out_vec as labels\n",
    "    label = file[:8]\n",
    "    out_vec.append(label)\n",
    "input_arrays = np.stack(matrices, axis=0)\n",
    "inDa_val = input_arrays.reshape((3000, 10, 20, 1))\n",
    "inDa_val.dtype\n",
    "inDa_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1a87f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### VALIDATION labels\n",
    "labels =out_vec\n",
    "# converting string values to integer calsses\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Initialize a LabelEncoder object\n",
    "label_encoder = LabelEncoder()\n",
    "# Fit the LabelEncoder to your string list and transform the string values into integer classes\n",
    "label_int = label_encoder.fit_transform(labels)\n",
    "#from keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "ouLa_val =to_categorical(label_int)\n",
    "ouLa_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27151bdc",
   "metadata": {},
   "source": [
    "# CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d41342",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CNN\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Conv2D(64, kernel_size=(3, 3),padding = \"same\", activation=\"relu\", input_shape=(10,20,1)))\n",
    "model.add(layers.Conv2D(256, kernel_size=(3, 3), activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation=\"relu\"))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(128, activation=\"relu\"))\n",
    "model.add(layers.Dropout(0.1))\n",
    "model.add(layers.Dense(3, activation=\"softmax\"))\n",
    "\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.0001,\n",
    "    beta_1=0.8,\n",
    "    beta_2=0.88,\n",
    "    #momentum=0.4,\n",
    "    epsilon=1e-07,)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "es = EarlyStopping(monitor='val_accuracy', patience=10, verbose=1)\n",
    "history = model.fit(inDa_trn, ouLa_trn, batch_size=96, epochs=35,validation_data=(inDa_tst, ouLa_tst), callbacks=[es] )\n",
    "print(history.history.keys())\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(inDa_val, ouLa_val)\n",
    "# print(\"Test Loss:\", loss)\n",
    "# print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9a3ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making confusion matrix to find percentage of false positives an dfalse negatives\n",
    "# use of test data to make predictions based on the model fitted\n",
    "lable_predicted = model.predict(inDa_val)\n",
    "lable_predicted_categories = np.argmax(lable_predicted, axis=1)\n",
    "label_actual = np.argmax(ouLa_val, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e48db97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calculaiton of confusion matrix\\\n",
    "cm = confusion_matrix(label_actual, lable_predicted_categories)\n",
    "print(cm)\n",
    "type(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97b5b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterating through numpy array to convert the values into percentage\n",
    "\n",
    "oneD_total = np.sum(cm, axis =1)\n",
    "cm_perc = cm/oneD_total[:,np.newaxis]\n",
    "cm_perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e238f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [0,1,2] # the vector defines three classes of selection types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd2d7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graphical visualization of the confusion matrix in the form of heatmap\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm_perc,  annot=True, cmap ='Blues', xticklabels =  class_names, yticklabels = class_names)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8d49dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_2d = np.array([[1, 2, 3],\n",
    "                     [4, 5, 6],\n",
    "                     [7, 8, 9]])\n",
    "\n",
    "# Calculate the sum of each 1D array (row)\n",
    "row_sums = np.sum(array_2d, axis=1)\n",
    "row_sums"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
