{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7646f847",
   "metadata": {},
   "outputs": [],
   "source": [
    "### loading libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bf57219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n",
      "Device name: /physical_device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# Check available devices\n",
    "devices = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if len(devices) > 0:\n",
    "    print(\"GPU is available\")\n",
    "    for device in devices:\n",
    "        print(\"Device name:\", device.name)\n",
    "else:\n",
    "    print(\"No GPU is available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be167a8b",
   "metadata": {},
   "source": [
    "## Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95e94e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/uufs/chpc.utah.edu/common/home/gompert-group4/projects/fluctCNN/DatafromUpdataCodeAugust25th/Trn\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(45000, 10, 20, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################ TRAINING DATA \n",
    "# changing directory to the data folder\n",
    "%cd /uufs/chpc.utah.edu/common/home/gompert-group4/projects/fluctCNN/DatafromUpdataCodeAugust25th/Trn/\n",
    "\n",
    "directory_path ='/uufs/chpc.utah.edu/common/home/gompert-group4/projects/fluctCNN/DatafromUpdataCodeAugust25th/Trn/'\n",
    "### making a list of all csv files\n",
    "csv_files = [file for file in os.listdir(directory_path) if file.endswith('.csv')]\n",
    "\n",
    "### processing the list of csv files to make arrays of input matrices and extracting output labels \n",
    "matrices = []\n",
    "out_vec = []\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file, header=None, sep=' ', dtype='float32')\n",
    "    matrices.append(df)\n",
    "    # appending first five letters to out_vec as labels\n",
    "    label = file[0:8]\n",
    "    out_vec.append(label)\n",
    "input_arrays = np.stack(matrices)\n",
    "inDa_trn = input_arrays.reshape((45000, 10, 20, 1))\n",
    "inDa_trn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcb10ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45000, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######### TRAINIG labels\n",
    "labels =out_vec\n",
    "# converting string values to integer calsses\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Initialize a LabelEncoder object\n",
    "label_encoder = LabelEncoder()\n",
    "# Fit the LabelEncoder to your string list and transform the string values into integer classes\n",
    "label_int = label_encoder.fit_transform(labels)\n",
    "#from keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "ouLa_trn =to_categorical(label_int)\n",
    "ouLa_trn.shape\n",
    "#print(ouLa_trn)\n",
    "ouLa_trn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b478579",
   "metadata": {},
   "source": [
    "## Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02db96b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/uufs/chpc.utah.edu/common/home/gompert-group4/projects/fluctCNN/DatafromUpdataCodeAugust25th/Tst\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15000, 10, 20, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################ TEST DATA \n",
    "# changing directory to the data folder\n",
    "%cd /uufs/chpc.utah.edu/common/home/gompert-group4/projects/fluctCNN/DatafromUpdataCodeAugust25th/Tst/\n",
    "# importing test set\n",
    "directory_path ='/uufs/chpc.utah.edu/common/home/gompert-group4/projects/fluctCNN/DatafromUpdataCodeAugust25th/Tst/'\n",
    "### making a list of all csv files\n",
    "csv_files_t = [file for file in os.listdir(directory_path) if file.endswith('.csv')]\n",
    "\n",
    "### processing the list of csv files to make arrays of input matrices and extracting output labels \n",
    "matrices = []\n",
    "out_vec = []\n",
    "for file in csv_files_t:\n",
    "    df = pd.read_csv(file, header=None, sep=' ', dtype='float32')\n",
    "    matrices.append(df)\n",
    "    # appending first five letters to out_vec as labels\n",
    "    label = file[0:8]\n",
    "    out_vec.append(label)\n",
    "input_arrays = np.stack(matrices)\n",
    "inDa_tst = input_arrays.reshape((15000, 10, 20, 1))\n",
    "inDa_tst.dtype\n",
    "inDa_tst.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "129028fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######### TEST labels\n",
    "labels =out_vec\n",
    "# converting string values to integer calsses\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Initialize a LabelEncoder object\n",
    "label_encoder = LabelEncoder()\n",
    "# Fit the LabelEncoder to your string list and transform the string values into integer classes\n",
    "label_int = label_encoder.fit_transform(labels)\n",
    "#from keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "ouLa_tst =to_categorical(label_int)\n",
    "ouLa_tst.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791d0a8f",
   "metadata": {},
   "source": [
    "## Validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005c5be3",
   "metadata": {},
   "source": [
    "#### Independent validation set generated afresh from the simulation script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ffdba8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/uufs/chpc.utah.edu/common/home/gompert-group4/projects/fluctCNN/DatafromUpdataCodeAugust25th/val\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3000, 10, 20, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################ VALIDATION DATA \n",
    "# changing directory to the data folder\n",
    "%cd /uufs/chpc.utah.edu/common/home/gompert-group4/projects/fluctCNN/DatafromUpdataCodeAugust25th/val/\n",
    "# importing validation set\n",
    "directory_path ='/uufs/chpc.utah.edu/common/home/gompert-group4/projects/fluctCNN/DatafromUpdataCodeAugust25th/val/'\n",
    "### making a list of all csv files\n",
    "csv_files_v = [file for file in os.listdir(directory_path) if file.endswith('.csv')]\n",
    "#print(len(csv_files))\n",
    "### processing the list of csv files to make arrays of input matrices and extracting output labels \n",
    "matrices = []\n",
    "out_vec = []\n",
    "for file in csv_files_v:\n",
    "    df = pd.read_csv(file, header=None, sep=' ', dtype='float32')\n",
    "    matrices.append(df)\n",
    "    # appending first five letters to out_vec as labels\n",
    "    label = file[:8]\n",
    "    out_vec.append(label)\n",
    "input_arrays = np.stack(matrices, axis=0)\n",
    "inDa_val = input_arrays.reshape((3000, 10, 20, 1))\n",
    "inDa_val.dtype\n",
    "inDa_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d1a87f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######### VALIDATION labels\n",
    "labels =out_vec\n",
    "# converting string values to integer calsses\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Initialize a LabelEncoder object\n",
    "label_encoder = LabelEncoder()\n",
    "# Fit the LabelEncoder to your string list and transform the string values into integer classes\n",
    "label_int = label_encoder.fit_transform(labels)\n",
    "#from keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "ouLa_val =to_categorical(label_int)\n",
    "ouLa_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27151bdc",
   "metadata": {},
   "source": [
    "# CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "24d41342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 1.0993 - accuracy: 0.3331 - val_loss: 1.0990 - val_accuracy: 0.3333\n",
      "Epoch 2/35\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 1.0986 - accuracy: 0.3366 - val_loss: 1.0986 - val_accuracy: 0.3330\n",
      "Epoch 3/35\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 1.0986 - accuracy: 0.3369 - val_loss: 1.0986 - val_accuracy: 0.3405\n",
      "Epoch 4/35\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 1.0984 - accuracy: 0.3406 - val_loss: 1.0986 - val_accuracy: 0.3332\n",
      "Epoch 5/35\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 1.0980 - accuracy: 0.3447 - val_loss: 1.0981 - val_accuracy: 0.3425\n",
      "Epoch 6/35\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 1.0968 - accuracy: 0.3578 - val_loss: 1.0977 - val_accuracy: 0.3479\n",
      "Epoch 7/35\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 1.0954 - accuracy: 0.3596 - val_loss: 1.0966 - val_accuracy: 0.3492\n",
      "Epoch 8/35\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 1.0922 - accuracy: 0.3731 - val_loss: 1.0970 - val_accuracy: 0.3539\n",
      "Epoch 9/35\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 1.0894 - accuracy: 0.3792 - val_loss: 1.0946 - val_accuracy: 0.3582\n",
      "Epoch 10/35\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 1.0859 - accuracy: 0.3912 - val_loss: 1.0926 - val_accuracy: 0.3627\n",
      "Epoch 11/35\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 1.0805 - accuracy: 0.3969 - val_loss: 1.0906 - val_accuracy: 0.3745\n",
      "Epoch 12/35\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 1.0720 - accuracy: 0.4083 - val_loss: 1.0797 - val_accuracy: 0.3877\n",
      "Epoch 13/35\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 1.0517 - accuracy: 0.4280 - val_loss: 1.0415 - val_accuracy: 0.4152\n",
      "Epoch 14/35\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.9924 - accuracy: 0.4825 - val_loss: 0.9675 - val_accuracy: 0.5067\n",
      "Epoch 15/35\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.8664 - accuracy: 0.5665 - val_loss: 0.7720 - val_accuracy: 0.5875\n",
      "Epoch 16/35\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.7179 - accuracy: 0.6197 - val_loss: 0.6536 - val_accuracy: 0.6196\n",
      "Epoch 17/35\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.6236 - accuracy: 0.6499 - val_loss: 0.5613 - val_accuracy: 0.6430\n",
      "Epoch 18/35\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.5734 - accuracy: 0.6638 - val_loss: 0.5354 - val_accuracy: 0.6532\n",
      "Epoch 19/35\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.5488 - accuracy: 0.6709 - val_loss: 0.5331 - val_accuracy: 0.6497\n",
      "Epoch 20/35\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.5405 - accuracy: 0.6771 - val_loss: 0.5201 - val_accuracy: 0.6560\n",
      "Epoch 21/35\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.5289 - accuracy: 0.6838 - val_loss: 0.5217 - val_accuracy: 0.6525\n",
      "Epoch 22/35\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.5236 - accuracy: 0.6843 - val_loss: 0.5224 - val_accuracy: 0.6526\n",
      "Epoch 23/35\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.5137 - accuracy: 0.6904 - val_loss: 0.5024 - val_accuracy: 0.6583\n",
      "Epoch 24/35\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.5127 - accuracy: 0.6944 - val_loss: 0.5374 - val_accuracy: 0.6515\n",
      "Epoch 25/35\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.5003 - accuracy: 0.7003 - val_loss: 0.5018 - val_accuracy: 0.6615\n",
      "Epoch 26/35\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.5013 - accuracy: 0.7022 - val_loss: 0.5129 - val_accuracy: 0.6539\n",
      "Epoch 27/35\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.4955 - accuracy: 0.7097 - val_loss: 0.5096 - val_accuracy: 0.6599\n",
      "Epoch 28/35\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.4931 - accuracy: 0.7088 - val_loss: 0.5274 - val_accuracy: 0.6563\n",
      "Epoch 29/35\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.4899 - accuracy: 0.7142 - val_loss: 0.5172 - val_accuracy: 0.6591\n",
      "Epoch 30/35\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.4820 - accuracy: 0.7204 - val_loss: 0.5311 - val_accuracy: 0.6517\n",
      "Epoch 31/35\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.4838 - accuracy: 0.7236 - val_loss: 0.5119 - val_accuracy: 0.6577\n",
      "Epoch 32/35\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.4758 - accuracy: 0.7269 - val_loss: 0.5219 - val_accuracy: 0.6547\n",
      "Epoch 33/35\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.4765 - accuracy: 0.7311 - val_loss: 0.5053 - val_accuracy: 0.6570\n",
      "Epoch 34/35\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.4686 - accuracy: 0.7347 - val_loss: 0.5220 - val_accuracy: 0.6535\n",
      "Epoch 35/35\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.4620 - accuracy: 0.7414 - val_loss: 0.5367 - val_accuracy: 0.6522\n",
      "Epoch 00035: early stopping\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5370 - accuracy: 0.6557\n"
     ]
    }
   ],
   "source": [
    "### CNN\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Conv2D(64, kernel_size=(3, 3),padding = \"same\", activation=\"relu\", input_shape=(10,20,1)))\n",
    "model.add(layers.Conv2D(256, kernel_size=(3, 3), activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation=\"relu\"))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(128, activation=\"relu\"))\n",
    "model.add(layers.Dropout(0.1))\n",
    "model.add(layers.Dense(3, activation=\"softmax\"))\n",
    "\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.0001,\n",
    "    beta_1=0.8,\n",
    "    beta_2=0.88,\n",
    "    #momentum=0.4,\n",
    "    epsilon=1e-07,)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "es = EarlyStopping(monitor='val_accuracy', patience=10, verbose=1)\n",
    "model.fit(inDa_trn, ouLa_trn, batch_size=96, epochs=35,validation_data=(inDa_tst, ouLa_tst), callbacks=[es] )\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(inDa_val, ouLa_val)\n",
    "# print(\"Test Loss:\", loss)\n",
    "# print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9a3ef5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
